{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d63dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (5.10.4)\n",
      "Requirement already satisfied: importnb in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (2023.11.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tensorflow_datasets in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: transformers in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (2.20.0)\n",
      "Collecting resource\n",
      "  Downloading Resource-0.2.1-py2.py3-none-any.whl.metadata (478 bytes)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from nbformat) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from nbformat) (4.22.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from importnb) (7.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: array-record in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (0.4.1)\n",
      "Requirement already satisfied: click in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (1.5.2)\n",
      "Requirement already satisfied: promise in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (6.0.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: toml in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorflow_datasets) (4.66.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Collecting JsonForm>=0.0.2 (from resource)\n",
      "  Downloading JsonForm-0.0.2.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting JsonSir>=0.0.2 (from resource)\n",
      "  Downloading JsonSir-0.0.2.tar.gz (2.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-easyconfig>=0.1.0 (from resource)\n",
      "  Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl.metadata (462 bytes)\n",
      "Requirement already satisfied: zipp in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.19.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (306)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tqdm->tensorflow_datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\saink\\pycharmprojects\\aiffel_dlthon01\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Downloading Resource-0.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl (5.4 kB)\n",
      "Building wheels for collected packages: JsonForm, JsonSir\n",
      "  Building wheel for JsonForm (setup.py): started\n",
      "  Building wheel for JsonForm (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonForm: filename=JsonForm-0.0.2-py3-none-any.whl size=3338 sha256=02a2ac734e4319deaf15a980ae8d745b4463777b133a839314328eb13180c91f\n",
      "  Stored in directory: c:\\users\\saink\\appdata\\local\\pip\\cache\\wheels\\2e\\bd\\ab\\c1026535edf314ce2b0d7ba3b2dd0ca67bfb5bae2cb301510f\n",
      "  Building wheel for JsonSir (setup.py): started\n",
      "  Building wheel for JsonSir (setup.py): finished with status 'done'\n",
      "  Created wheel for JsonSir: filename=JsonSir-0.0.2-py3-none-any.whl size=4775 sha256=0040f4821ef28a2b3c9f36837886c23be42d7e78dc3e402790e8cf6ea991ecc0\n",
      "  Stored in directory: c:\\users\\saink\\appdata\\local\\pip\\cache\\wheels\\bb\\e7\\72\\08831f4f1927bfcb155f0a971e253bfe677172cebea1332b51\n",
      "Successfully built JsonForm JsonSir\n",
      "Installing collected packages: JsonSir, python-easyconfig, JsonForm, resource\n",
      "Successfully installed JsonForm-0.0.2 JsonSir-0.0.2 python-easyconfig-0.1.7 resource-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat importnb pandas matplotlib numpy tensorflow scikit-learn torch tensorflow_datasets transformers datasets resource\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# import os\n",
    "# import re\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "# from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94e027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이블러리 불러오기\n",
    "import os\n",
    "import importlib\n",
    "from importnb import Notebook\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41151a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'resource'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# 가져온 모듈을 globals()에 추가합니다.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m---> 21\u001b[0m \u001b[43mfile_import\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutills\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m file_import(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mfile_import\u001b[1;34m(folderName)\u001b[0m\n\u001b[0;32m     12\u001b[0m module_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolderName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Notebook():\n\u001b[1;32m---> 15\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 가져온 모듈을 globals()에 추가합니다.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mglobals\u001b[39m()[module_name] \u001b[38;5;241m=\u001b[39m module\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\importnb\\loader.py:190\u001b[0m, in \u001b[0;36mLoader.exec_module\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alias:\n\u001b[0;32m    188\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(alias, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\importnb\\loader.py:181\u001b[0m, in \u001b[0;36mLoader.exec_module\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_code() returns None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mCO_COROUTINE \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _get_co_flags_set(code\u001b[38;5;241m.\u001b[39mco_flags):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# if there isn't any async non sense then we proceed with convention.\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     \u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_frames_removed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maexec_module_sync(module)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\utills\\pre.ipynb:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_metadata \u001b[38;5;28;01mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m _call_metadata\u001b[38;5;241m.\u001b[39mCallMetadata()\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# natural than having to import a third party module.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m community\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamBasedBuilder\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuilderConfig\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2023 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Community dataset API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock_builtin_to_use_gfile\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock_huggingface_import\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder_cls_from_module\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_builder\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_info\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m reader_lib\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registered\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_builder \u001b[38;5;28;01mas\u001b[39;00m split_builder_lib\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splits \u001b[38;5;28;01mas\u001b[39;00m splits_lib\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_compat\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splits \u001b[38;5;28;01mas\u001b[39;00m splits_lib\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m writer \u001b[38;5;28;01mas\u001b[39;00m writer_lib\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shard_utils\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mTYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\writer.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lazy_imports_lib\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m naming\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shuffle\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m file_utils\n",
      "File \u001b[1;32mc:\\Users\\saink\\PycharmProjects\\aiffel_DLthon01\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\shuffle.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mresource\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterator, List, Optional\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'resource'"
     ]
    }
   ],
   "source": [
    "def file_import(folderName):\n",
    "    # 현재 작업 디렉토리를 가져옵니다.\n",
    "    current_dir = os.getcwd()\n",
    "    models_dir = os.path.join(current_dir, f'{folderName}')\n",
    "\n",
    "    # models 디렉토리 내의 모든 .ipynb 파일을 가져옵니다.\n",
    "    notebook_files = [f for f in os.listdir(models_dir) if f.endswith('.ipynb')]\n",
    "\n",
    "    # 모든 .ipynb 파일을 동적으로 import합니다.\n",
    "    for notebook_file in notebook_files:\n",
    "        module_name = notebook_file[:-6]  # .ipynb 확장자 제거\n",
    "        module_path = f'{folderName}.{module_name}'\n",
    "\n",
    "        with Notebook():\n",
    "            module = importlib.import_module(module_path)\n",
    "\n",
    "        # 가져온 모듈을 globals()에 추가합니다.\n",
    "        globals()[module_name] = module\n",
    "\n",
    "\n",
    "file_import('utills')\n",
    "file_import('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0919a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전역 변수 설정\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b17df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train_data_path =\"./data/train.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "train_data.head()\n",
    "\n",
    "with open('./data/test.json') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ab7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idx      class                                       conversation\n",
      "0    0      협박 대화  지금 너 스스로를 죽여달라고 애원하는 것인가?\\n 아닙니다. 죄송합니다.\\n 죽을 ...\n",
      "1    1      협박 대화  길동경찰서입니다.\\n9시 40분 마트에 폭발물을 설치할거다.\\n네?\\n똑바로 들어 ...\n",
      "2    2  기타 괴롭힘 대화  너 되게 귀여운거 알지? 나보다 작은 남자는 첨봤어.\\n그만해. 니들 놀리는거 재미...\n",
      "3    3      갈취 대화  어이 거기\\n예??\\n너 말이야 너. 이리 오라고\\n무슨 일.\\n너 옷 좋아보인다?...\n",
      "4    4      갈취 대화  저기요 혹시 날이 너무 뜨겁잖아요? 저희 회사에서 이 선크림 파는데 한 번 손등에 ...\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac2bc85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 셋 설정\n",
    "expSet = [{'pre':'pre.preprocess_sentence',\n",
    "           'train_test_split':{'test_size':0.2},\n",
    "           'model':'klue_roberta_base'\n",
    "          }\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33db9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리\n",
      "데이터 분할\n",
      "모델 설정\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86a538b5908450898bcd2077bb930cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccabee57799945c7a50373fe6b551727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for exp in expSet:\n",
    "    tmp = train_data.copy()\n",
    "    # 전처리\n",
    "    if 'pre' in exp:\n",
    "        print('전처리')\n",
    "        function_to_call = f'tmp[\"pre_\"] = tmp[\"conversation\"].apply(pre.preprocess_sentence)'\n",
    "        exec(f'tmp[\"pre\"] = {function_to_call}')\n",
    "    # 데이터 분할\n",
    "    if 'train_test_split' in exp:\n",
    "        print('데이터 분할')\n",
    "        train_df, test_df = train_test_split(tmp, test_size=exp['train_test_split']['test_size']\n",
    "                                             , stratify=tmp['class'], random_state=seed)\n",
    "    \n",
    "    # 모델 불러오기\n",
    "    print('모델 설정')\n",
    "    x = exp['model']\n",
    "    function_to_call = f'{x}.model(train_df, test_df)'\n",
    "    exec(f'trainer = {function_to_call}')\n",
    "#     model_function = globals()[exp['model']]\n",
    "#     trainer = eval(f'{model_function}(train_df, test_df)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301d25ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "klue_roberta_base.model(train_df, test_df)\n"
     ]
    }
   ],
   "source": [
    "# klue_roberta_base.model()\n",
    "\n",
    "for exp in expSet:\n",
    "    x = exp['model']\n",
    "    print(f'{x}.model(train_df, test_df)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4dab9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"a8fa41ae061743cfb789129f6a363a02ff8ecebc\"\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"test\")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "940fc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       idx        class                                       conversation  \\\n",
      "145    145    기타 괴롭힘 대화  야 못생긴놈\\n뭐야 그만해\\n얼레리꼴레리 너는 눈도 작고 코도작고 못생겼냐\\n그만해...   \n",
      "173    173  직장 내 괴롭힘 대화  이사원 이업무좀 내일까지 할수있나\\n저 지금 하고있는거도있고 내일까지는 힘들거같습니...   \n",
      "2364  2364        협박 대화  시끄러워 살수가 없어요\\n우리집은 아이도 교육시켜 조용히 걸어요\\n지금도 아이 소리...   \n",
      "1316  1316  직장 내 괴롭힘 대화  김대리 이거 프로젝트 왜아직까지 완료가안된거지?\\n과장님 프로젝트 다음주까지 연기되...   \n",
      "608    608    기타 괴롭힘 대화  어이 택시 용호동가줘\\n 네\\n 아니 이쪽길말고 저리가야지\\n 이쪽길이 빠릅니다 손...   \n",
      "\n",
      "                                                    pre  \\\n",
      "145   야 못생긴놈 뭐야 그만해 얼레리꼴레리 너는 눈도 작고 코도작고 못생겼냐 그만해 선생...   \n",
      "173   이사원 이업무좀 내일까지 할수있나 저 지금 하고있는거도있고 내일까지는 힘들거같습니다...   \n",
      "2364  시끄러워 살수가 없어요 우리집은 아이도 교육시켜 조용히 걸어요 지금도 아이 소리 지...   \n",
      "1316  김대리 이거 프로젝트 왜아직까지 완료가안된거지 ? 과장님 프로젝트 다음주까지 연기되...   \n",
      "608   어이 택시 용호동가줘 네 아니 이쪽길말고 저리가야지 이쪽길이 빠릅니다 손님 하 . ...   \n",
      "\n",
      "                                                   pre_  \n",
      "145   야 못생긴놈 뭐야 그만해 얼레리꼴레리 너는 눈도 작고 코도작고 못생겼냐 그만해 선생...  \n",
      "173   이사원 이업무좀 내일까지 할수있나 저 지금 하고있는거도있고 내일까지는 힘들거같습니다...  \n",
      "2364  시끄러워 살수가 없어요 우리집은 아이도 교육시켜 조용히 걸어요 지금도 아이 소리 지...  \n",
      "1316  김대리 이거 프로젝트 왜아직까지 완료가안된거지 ? 과장님 프로젝트 다음주까지 연기되...  \n",
      "608   어이 택시 용호동가줘 네 아니 이쪽길말고 저리가야지 이쪽길이 빠릅니다 손님 하 . ...  \n",
      "       idx      class                                       conversation  \\\n",
      "2885  2885      협박 대화  야 너 내말안들어? 내가 지금 말하는건 충고아니고 명령이야\\n죄송합니다\\n내가 요새...   \n",
      "1258  1258      협박 대화  너 왜 어제 연락이 없었어.\\n어제 바빠서 그랬어. 왜 또 그래?\\n내가 분명 말했...   \n",
      "1014  1014  기타 괴롭힘 대화  여기 맛집 아닌거 같아요. 여기 오지 마세요.\\n 저기요? 사전에 허락도 없이 지금...   \n",
      "31      31  기타 괴롭힘 대화  니가 나 따라한다는 애구나?\\n 내가? 나 너 안따라해.\\n머라는거야. 여기 사진 ...   \n",
      "3679  3679  기타 괴롭힘 대화  근데 너 아빠랑 왜 그렇게 얼굴이 달라?\\n아 우리 엄마랑 아빠가 이혼하셔서 엄마가...   \n",
      "\n",
      "                                                    pre  \\\n",
      "2885  야 너 내말안들어 ? 내가 지금 말하는건 충고아니고 명령이야 죄송합니다 내가 요새 ...   \n",
      "1258  너 왜 어제 연락이 없었어 . 어제 바빠서 그랬어 . 왜 또 그래 ? 내가 분명 말...   \n",
      "1014  여기 맛집 아닌거 같아요 . 여기 오지 마세요 . 저기요 ? 사전에 허락도 없이 지...   \n",
      "31    니가 나 따라한다는 애구나 ? 내가 ? 나 너 안따라해 . 머라는거야 . 여기 사진...   \n",
      "3679  근데 너 아빠랑 왜 그렇게 얼굴이 달라 ? 아 우리 엄마랑 아빠가 이혼하셔서 엄마가...   \n",
      "\n",
      "                                                   pre_  \n",
      "2885  야 너 내말안들어 ? 내가 지금 말하는건 충고아니고 명령이야 죄송합니다 내가 요새 ...  \n",
      "1258  너 왜 어제 연락이 없었어 . 어제 바빠서 그랬어 . 왜 또 그래 ? 내가 분명 말...  \n",
      "1014  여기 맛집 아닌거 같아요 . 여기 오지 마세요 . 저기요 ? 사전에 허락도 없이 지...  \n",
      "31    니가 나 따라한다는 애구나 ? 내가 ? 나 너 안따라해 . 머라는거야 . 여기 사진...  \n",
      "3679  근데 너 아빠랑 왜 그렇게 얼굴이 달라 ? 아 우리 엄마랑 아빠가 이혼하셔서 엄마가...  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f7f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
